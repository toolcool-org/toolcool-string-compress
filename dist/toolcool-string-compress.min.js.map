{
  "version": 3,
  "sources": ["../src/encoder.ts", "../src/decoder.ts", "../src/index.ts"],
  "sourcesContent": ["const TCEncoder = (text: string) => {\n\n    const searchBuffer: Map<number, number> = new Map();\n    const result = [];\n\n    const encoder = new TextEncoder();\n    const view = encoder.encode(text); // Uint8Array\n    const len = view.length;\n\n    let i=0;\n    while(i<len){\n        const byte = view[i];\n\n        if(searchBuffer.has(byte)){\n            // The character is repeated ---> we can create the token.\n            // Try to maximize how much text the token is referencing.\n            let previousCharacterIndex = searchBuffer.get(byte) ?? 0;\n            let currentCharacterIndex = i;\n            const tokenOffset = i - previousCharacterIndex;\n\n            const tokenValue = [];\n            while(text[previousCharacterIndex] === text[currentCharacterIndex] && currentCharacterIndex < len){\n                tokenValue.push(view[currentCharacterIndex]);\n                previousCharacterIndex++;\n                currentCharacterIndex++;\n            }\n\n            const token = `<${ tokenOffset },${ tokenValue.length }>`;\n            if(tokenValue.length > token.length){\n                // place the token\n                const tokenUint8Array = encoder.encode(token);\n                result.push(...tokenUint8Array);\n            }\n            else{\n                // token size is bigger that the actual text --> place the text\n                result.push(...tokenValue);\n            }\n\n            i += tokenValue.length;\n        }\n        else{\n            // New non-repeated characters just added to the result as a plain text.\n            searchBuffer.set(byte, i);\n            result.push(byte)\n            i++;\n        }\n    }\n\n    return new TextDecoder().decode(new Uint8Array(result));\n};\n\nexport default TCEncoder;", "\nconst decodeToken = (encoded: string, i: number, offset: number, length: number) => {\n    let tokeValue = '';\n    const startIndex = i - offset;\n\n    if(offset < length){\n        const char = encoded[startIndex];\n        tokeValue += char.repeat(length);\n    }\n    else{\n        const endIndex = Math.min(startIndex + length, encoded.length);\n        for(let t=startIndex; t<endIndex; t++){\n            tokeValue += encoded[t];\n        }\n    }\n\n    return tokeValue;\n};\n\nconst getNumber = (encoded: string, i: number) => {\n    let result = '';\n    let t = i;\n\n    while(Number.isInteger(Number(encoded[t])) && t<encoded.length){\n        result += encoded[t];\n        t++;\n    }\n    return result;\n};\n\nconst TCDecoder = (encoded: string) => {\n    let decoded = '';\n\n    const len = encoded.length;\n\n    let i = 0;\n    while(i < len){\n        const char = encoded[i];\n\n        if(char === '<'){\n            const offset = getNumber(encoded, i + 1);\n            let length = '';\n            let isValid = offset.length > 0 && Number.isInteger(Number(offset));\n            if(isValid){\n                length = getNumber(encoded, i + offset.length + 2);\n                isValid = length.length > 0 && Number.isInteger(Number(length));\n            }\n\n            if(!isValid){\n                decoded += char;\n                i++;\n            }\n            else{\n                const tokenValue = decodeToken(encoded, i, Number(offset), Number(length));\n                decoded += tokenValue;\n                i += offset.length + length.length + 3;\n            }\n        }\n        else{\n            decoded += char;\n            i++;\n        }\n    }\n\n    return decoded;\n};\n\nexport default TCDecoder;", "import TCEncoder from './encoder';\nimport TCDecoder from './decoder';\n\ndeclare global {\n    interface Window {\n        TCEncoder: typeof TCEncoder;\n        TCDecoder: typeof TCDecoder;\n    }\n}\n\nwindow.TCEncoder = TCEncoder;\nwindow.TCDecoder = TCDecoder;"],
  "mappings": ";;;;;;;MAAA,IAAMA,EAAaC,GAAiB,CAApC,IAAAC,EAEI,IAAMC,EAAoC,IAAI,IACxCC,EAAS,CAAC,EAEVC,EAAU,IAAI,YACdC,EAAOD,EAAQ,OAAOJ,CAAI,EAC1BM,EAAMD,EAAK,OAEbE,EAAE,EACN,KAAMA,EAAED,GAAI,CACR,IAAME,EAAOH,EAAKE,GAElB,GAAGL,EAAa,IAAIM,CAAI,EAAE,CAGtB,IAAIC,GAAyBR,EAAAC,EAAa,IAAIM,CAAI,IAArB,KAAAP,EAA0B,EACnDS,EAAwBH,EACtBI,EAAcJ,EAAIE,EAElBG,EAAa,CAAC,EACpB,KAAMZ,EAAKS,KAA4BT,EAAKU,IAA0BA,EAAwBJ,GAC1FM,EAAW,KAAKP,EAAKK,EAAsB,EAC3CD,IACAC,IAGJ,IAAMG,EAAQ,IAAKF,KAAiBC,EAAW,UAC/C,GAAGA,EAAW,OAASC,EAAM,OAAO,CAEhC,IAAMC,EAAkBV,EAAQ,OAAOS,CAAK,EAC5CV,EAAO,KAAK,GAAGW,CAAe,CAClC,MAGIX,EAAO,KAAK,GAAGS,CAAU,EAG7BL,GAAKK,EAAW,MACpB,MAGIV,EAAa,IAAIM,EAAMD,CAAC,EACxBJ,EAAO,KAAKK,CAAI,EAChBD,GAER,CAEA,OAAO,IAAI,YAAY,EAAE,OAAO,IAAI,WAAWJ,CAAM,CAAC,CAC1D,EAEOY,EAAQhB,EClDf,IAAMiB,EAAc,CAACC,EAAiBC,EAAWC,EAAgBC,IAAmB,CAChF,IAAIC,EAAY,GACVC,EAAaJ,EAAIC,EAEvB,GAAGA,EAASC,EAAO,CACf,IAAMG,EAAON,EAAQK,GACrBD,GAAaE,EAAK,OAAOH,CAAM,CACnC,KACI,CACA,IAAMI,EAAW,KAAK,IAAIF,EAAaF,EAAQH,EAAQ,MAAM,EAC7D,QAAQQ,EAAEH,EAAYG,EAAED,EAAUC,IAC9BJ,GAAaJ,EAAQQ,EAE7B,CAEA,OAAOJ,CACX,EAEMK,EAAY,CAACT,EAAiBC,IAAc,CAC9C,IAAIS,EAAS,GACTF,EAAIP,EAER,KAAM,OAAO,UAAU,OAAOD,EAAQQ,EAAE,CAAC,GAAKA,EAAER,EAAQ,QACpDU,GAAUV,EAAQQ,GAClBA,IAEJ,OAAOE,CACX,EAEMC,EAAaX,GAAoB,CACnC,IAAIY,EAAU,GAERC,EAAMb,EAAQ,OAEhBC,EAAI,EACR,KAAMA,EAAIY,GAAI,CACV,IAAMP,EAAON,EAAQC,GAErB,GAAGK,IAAS,IAAI,CACZ,IAAMJ,EAASO,EAAUT,EAASC,EAAI,CAAC,EACnCE,EAAS,GACTW,EAAUZ,EAAO,OAAS,GAAK,OAAO,UAAU,OAAOA,CAAM,CAAC,EAMlE,GALGY,IACCX,EAASM,EAAUT,EAASC,EAAIC,EAAO,OAAS,CAAC,EACjDY,EAAUX,EAAO,OAAS,GAAK,OAAO,UAAU,OAAOA,CAAM,CAAC,GAG/D,CAACW,EACAF,GAAWN,EACXL,QAEA,CACA,IAAMc,EAAahB,EAAYC,EAASC,EAAG,OAAOC,CAAM,EAAG,OAAOC,CAAM,CAAC,EACzES,GAAWG,EACXd,GAAKC,EAAO,OAASC,EAAO,OAAS,CACzC,CACJ,MAEIS,GAAWN,EACXL,GAER,CAEA,OAAOW,CACX,EAEOI,EAAQL,ECzDf,OAAO,UAAYM,EACnB,OAAO,UAAYC",
  "names": ["TCEncoder", "text", "_a", "searchBuffer", "result", "encoder", "view", "len", "i", "byte", "previousCharacterIndex", "currentCharacterIndex", "tokenOffset", "tokenValue", "token", "tokenUint8Array", "encoder_default", "decodeToken", "encoded", "i", "offset", "length", "tokeValue", "startIndex", "char", "endIndex", "t", "getNumber", "result", "TCDecoder", "decoded", "len", "isValid", "tokenValue", "decoder_default", "encoder_default", "decoder_default"]
}
